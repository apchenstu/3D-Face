{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2, dlib, re, pyrender, trimesh\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import os.path as osp\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.transform import Rotation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadObj(file):\n",
    "    obj = {}\n",
    "    obj['v'],obj['vn'],obj['vt'],obj['f'] = [],[],[],[]\n",
    "    f = open(file, \"r\")\n",
    "    lines = f.readlines()\n",
    "    delimiters = \" \", \"//\", \"\\\\\",\"/\",\"\\\\\"\n",
    "    regexPattern = '|'.join(map(re.escape, delimiters))\n",
    "    for item in lines:\n",
    "        data = re.split(regexPattern, item)\n",
    "        if 'v' == data[0]:\n",
    "            obj['v'].append(np.array(data[1:]).astype('float'))\n",
    "        elif 'vt' == data[0]:\n",
    "            obj['vt'].append(np.array(data[1:]).astype('float'))\n",
    "        elif 'vn' == data[0]:\n",
    "            obj['vn'].append(np.array(data[1:]).astype('float'))\n",
    "        elif 'f' == data[0]:\n",
    "            obj['f'].append(np.array(data[1:]).astype('int32'))\n",
    "    \n",
    "    hasVN,hasVT = False,False\n",
    "    if len(obj['v']):\n",
    "        obj['v'] = np.vstack(obj['v'])\n",
    "    if len(obj['vn']):\n",
    "        hasVN = True\n",
    "        obj['vn'] = np.vstack(obj['vn'])\n",
    "    if len(obj['vt']):\n",
    "        hasVT = True\n",
    "        obj['vt'] = np.vstack(obj['vt'])\n",
    "    if len(obj['f']):\n",
    "        obj['f'] = np.vstack(obj['f'])\n",
    "    \n",
    "    f = np.ones((9,obj['f'].shape[0]))\n",
    "    if  hasVN and hasVT:\n",
    "        f = obj['f'][:,[0,3,6,2,5,8,1,4,7]].T\n",
    "    elif hasVN and obj['f'].shape[1]==6:\n",
    "        f[:6] = obj['f'][:,[0,2,4,1,3,5]].T\n",
    "    elif hasVT and obj['f'].shape[1]==6:\n",
    "        f[[0,1,2,6,7,8]] = obj['f'][:,[0,2,4,1,3,5]].T\n",
    "    else:\n",
    "        f[[0,1,2]] = obj['f'].T\n",
    "    obj['f'] = f.astype('uint32')-1\n",
    "    return obj\n",
    "\n",
    "def saveObj(file,obj):\n",
    "    f = open(file, \"w\")\n",
    "    for item in obj['v']:\n",
    "        print('v %.4f %.4f %.4f'%tuple(item),file=f)\n",
    "    if len(obj['vn']):\n",
    "        for item in obj['vn']:\n",
    "            print('vn %.4f %.4f %.4f'%tuple(item),file=f)\n",
    "    if len(obj['vt']):\n",
    "        for item in obj['vt']:\n",
    "            print('vt %.4f %.4f'%tuple(item),file=f)\n",
    "       \n",
    "    for item in obj['f'].T+1:\n",
    "        if len(obj['vn']) and len(obj['vt']):\n",
    "            print('f %d/%d/%d %d/%d/%d %d/%d/%d'%tuple(item[[0,3,6,2,5,8,1,4,7]]),file=f)\n",
    "        elif len(obj['vn']) :\n",
    "            print('f %d/%d %d/%d %d/%d'%tuple(item[[0,3,1,4,2,5]]),file=f)\n",
    "        elif len(obj['vt']):\n",
    "            print('f %d/%d %d/%d %d/%d'%tuple(item[[0,6,1,7,2,8]]),file=f)\n",
    "        else:\n",
    "            print('f %d %d %d'%tuple(item[:3]),file=f)\n",
    "    f.close()\n",
    "    \n",
    "def rect_to_bb(rect):\n",
    "    # take a bounding predicted by dlib and convert it\n",
    "    # to the format (x, y, w, h) as we would normally do\n",
    "    # with OpenCV\n",
    "    x = rect.left()\n",
    "    y = rect.top()\n",
    "    w = rect.right() - x\n",
    "    h = rect.bottom() - y\n",
    "\n",
    "    # return a tuple of (x, y, w, h)\n",
    "    return (x, y, w, h)\n",
    "\n",
    "def landmark_detect(gray):\n",
    "    rects = detector(gray, 1)\n",
    "    if len(rects)==0:\n",
    "        print('Couldn\\'t detect faces on the image.')\n",
    "        return\n",
    "        \n",
    "    rect = rects[0]\n",
    "    shape = predictor(gray, rect)\n",
    "    lm = np.array([[p.x, p.y] for p in shape.parts()])\n",
    "    return lm\n",
    "\n",
    "def angle2matrix(pose):\n",
    "    ''' compute Rotation Matrix from three Euler angles\n",
    "    '''\n",
    "    R_x = np.array([[1, 0, 0],\n",
    "                    [0, np.cos(pose[0]), -np.sin(pose[0])],\n",
    "                    [0, np.sin(pose[0]), np.cos(pose[0])]\n",
    "                    ])\n",
    "\n",
    "    R_y = np.array([[np.cos(pose[1]), 0, np.sin(pose[1])],\n",
    "                    [0, 1, 0],\n",
    "                    [-np.sin(pose[1]), 0, np.cos(pose[1])]\n",
    "                    ])\n",
    "\n",
    "    R_z = np.array([[np.cos(pose[2]), -np.sin(pose[2]), 0],\n",
    "                    [np.sin(pose[2]), np.cos(pose[2]), 0],\n",
    "                    [0, 0, 1]\n",
    "                    ])\n",
    "    R = np.dot(R_z, np.dot(R_y, R_x))\n",
    "    return R\n",
    "\n",
    "def isRotationMatrix(R):\n",
    "    Rt = np.transpose(R)\n",
    "    shouldBeIdentity = np.dot(Rt, R)\n",
    "    I = np.identity(3, dtype=R.dtype)\n",
    "    n = np.linalg.norm(I - shouldBeIdentity)\n",
    "    return n < 1e-6\n",
    "\n",
    "def matrix2angle(R):\n",
    "    #assert (isRotationMatrix(R))\n",
    "\n",
    "    sy = np.sqrt(R[0, 0] * R[0, 0] + R[1, 0] * R[1, 0])\n",
    "\n",
    "    singular = sy < 1e-6\n",
    "\n",
    "    if not singular:\n",
    "        x = np.arctan2(R[2, 1], R[2, 2])\n",
    "        y = np.arctan2(-R[2, 0], sy)\n",
    "        z = np.arctan2(R[1, 0], R[0, 0])\n",
    "    else:\n",
    "        x = np.arctan2(-R[1, 2], R[1, 1])\n",
    "        y = np.arctan2(-R[2, 0], sy)\n",
    "        z = 0\n",
    "\n",
    "    return np.array([x, y, z])\n",
    "\n",
    "\n",
    "def save_to_pts(lm,file):\n",
    "    f = open(file,'w')\n",
    "    print('version: 1\\nn_points:  68\\n{',file=f)\n",
    "    for i in range(68):\n",
    "        print('%d %d'%(lm[i,0],lm[i,1]),file=f)\n",
    "    print('}',file=f)\n",
    "    f.close()\n",
    "    \n",
    "def shape_to_np(shape, dtype=\"int\"):\n",
    "    coords = np.zeros((68, 2), dtype=dtype)\n",
    "\n",
    "    for i in range(0, 68):\n",
    "        coords[i] = (np.round(shape.part(i).x), np.round(shape.part(i).y))\n",
    "\n",
    "    return coords\n",
    "\n",
    "def load_imgs(path,size=512):\n",
    "    imgs,pts = [],[]\n",
    "    if os.path.isdir(path):\n",
    "        files = os.listdir(path)\n",
    "    else:\n",
    "        files = [path]\n",
    "    for item in files:\n",
    "        file = os.path.join(path,item)\n",
    "        img = cv2.resize(cv2.imread(file),(size,size))\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        lm = landmark_detect(gray)\n",
    "        if lm is None:\n",
    "            continue\n",
    "        pts.append(lm)\n",
    "        imgs.append(img)\n",
    "    pts,imgs = np.stack(pts,axis=0),np.stack(imgs,axis=0)\n",
    "    return imgs, pts\n",
    "\n",
    "def ortho(frustum):\n",
    "    left,right,bottom,top = frustum[:]\n",
    "    projection = np.eye(4)\n",
    "    projection[0,0], projection[1,1],projection[2,2] = 2/(right - left), 2/(top - bottom), -1\n",
    "    projection[0,3],projection[1,3] = -(right + left) / (right - left),  -(top + bottom) / (top - bottom)\n",
    "    return projection\n",
    "\n",
    "def render(mesh,fy,cam=np.eye(4),model=np.eye(4),resolution=[512,512]):\n",
    "\n",
    "    obj = pyrender.Mesh.from_trimesh(mesh, smooth=True)\n",
    "    fovY = 2*np.arctan(resolution[0]/2/fy)\n",
    "    # compose scene\n",
    "    scene = pyrender.Scene(ambient_light=[0.1, 0.1, 0.1], bg_color=[0, 0, 0])\n",
    "    camera = pyrender.PerspectiveCamera( yfov=fovY)\n",
    "    light = pyrender.DirectionalLight(color=[1.0, 1.0, 1.0], intensity=8)\n",
    "\n",
    "    scene.add(obj, pose=  model)\n",
    "    scene.add(light, pose=  model)\n",
    "    scene.add(camera, pose = cam)\n",
    "    \n",
    "    # render scene\n",
    "    r = pyrender.OffscreenRenderer(resolution[1], resolution[0])\n",
    "    color, depth = r.render(scene)\n",
    "    color,depth = color[::-1,::-1],depth[::-1,::-1]\n",
    "    return color,depth\n",
    "\n",
    "def render2(mesh,cam=np.eye(4),model=np.eye(4),scale=[1,1],resolution=[720,1280]):\n",
    "\n",
    "    obj = pyrender.Mesh.from_trimesh(mesh, smooth=True)\n",
    "\n",
    "    scene = pyrender.Scene(ambient_light=[1.0, 1.0, 1.0], bg_color=[0, 0, 0])\n",
    "    camera = pyrender.OrthographicCamera(xmag=1, ymag=resolution[0]/2/scale[1], znear=1e-3, zfar=10000.0)\n",
    "    light = pyrender.DirectionalLight(color=[1.0, 1.0, 1.0], intensity=2.0)\n",
    "\n",
    "    scene.add(obj, pose=  model)\n",
    "    scene.add(light, pose=  model)\n",
    "    scene.add(camera, pose = cam)\n",
    "    \n",
    "    # render scene\n",
    "    r = pyrender.OffscreenRenderer(resolution[1], resolution[0])\n",
    "    color, _ = r.render(scene)\n",
    "    \n",
    "    width = int(round(resolution[1]*scale[0]/scale[1]))\n",
    "    img = cv2.resize(color,(width,resolution[0]))\n",
    "    pad = (width - resolution[1])//2\n",
    "    right_pad = resolution[1] - width - abs(pad)\n",
    "    if pad >= 0:\n",
    "        img = img[:,pad:pad+resolution[1]]\n",
    "    elif pad < 0:\n",
    "        img = np.pad(img, ((0,0),(abs(pad),right_pad),(0,0)), 'edge')\n",
    "    \n",
    "    return img,_\n",
    "\n",
    "def solveCamera(model_points,image_points):\n",
    "    if 'ortho' == CameraMode:\n",
    "        extrinsic, affine, cameraMatrix = solveCamera_ortho(model_points,image_points)\n",
    "    else:\n",
    "        extrinsic, affine, cameraMatrix = solveCamera_perspect(model_points,image_points)\n",
    "    return extrinsic, affine, cameraMatrix\n",
    "        \n",
    "def solveCamera_perspect(model_points,image_points):\n",
    "    W,H = img_size\n",
    "    fov_y = 15\n",
    "    fov_y = fov_y/180*np.pi\n",
    "    f = H/2/np.tan(fov_y/2)\n",
    "\n",
    "    cx,cy = W/2,H/2\n",
    "    cameraMatrix = np.array([[f,0,cx],[0,f,cy],[0,0,1]]).astype('float')\n",
    "    distCoeffs = np.zeros((1,4))\n",
    "    \n",
    "    _, rvec, t = cv2.solvePnP(model_points, image_points,cameraMatrix,distCoeffs)#solvePnPRansac\n",
    "    r = Rotation.from_rotvec(rvec.reshape((-1))).as_matrix()\n",
    "    \n",
    "    extrins = np.hstack([r,t])\n",
    "    extrins = np.vstack([extrins,np.array([0,0,0,1])])\n",
    "    \n",
    "#     vertice = np.hstack((model_points,np.ones((model_points.shape[0],1))))\n",
    "#     vertice = np.dot(cameraMatrix,np.dot(extrins,vertice.T)[:3])\n",
    "#     vertice /= vertice[[2]]\n",
    "#     print(vertice[:2].T,image_points)\n",
    "\n",
    "    affine = np.dot(cameraMatrix,extrins[:3])[:3]\n",
    "    return extrins, affine,cameraMatrix\n",
    "\n",
    "def solveCamera_ortho(model_points,image_points):\n",
    "    # model_points, image_points N*M\n",
    "    A,b = np.zeros((2*model_points.shape[0],8)),np.zeros((2*model_points.shape[0],1))\n",
    "    ind = 0\n",
    "    for model_point, image_point in zip(model_points,image_points):\n",
    "        A[2*ind,:3],A[2*ind+1,4:7] = model_point[:3],model_point[:3]\n",
    "        A[2*ind,3],A[2*ind+1,7] = 1,1\n",
    "        b[2*ind:2*ind+2] = image_point.reshape((-1,1))\n",
    "        ind += 1\n",
    "    affine,_,_,_ = np.linalg.lstsq(A,b,rcond=None)\n",
    "    affine = affine.reshape((2,4))\n",
    "    \n",
    "    \n",
    "    norms = np.linalg.norm(affine[:,:3],axis=1)\n",
    "    scale = norms\n",
    "    R = affine[:,:3]/norms.reshape((-1,1))\n",
    "    R1,R2 = R[0],R[1]\n",
    "    R3 = np.cross(R1,R2)\n",
    "    R3 /= np.linalg.norm(R3)\n",
    "    R = np.vstack((R1,R2,R3))\n",
    "\n",
    "    U,S,V = np.linalg.svd(R)\n",
    "    R_ortho = np.dot(U, V)\n",
    "    if np.linalg.det(R_ortho) < 0:\n",
    "        U[2,0] = -U[2,0]\n",
    "        R_ortho = np.dot(U, V)\n",
    "    t1,t2 = affine[0,3],affine[1,3]\n",
    "\n",
    "    MV = np.zeros((4,4))\n",
    "    MV[:3,:3] = R_ortho[:3]\n",
    "    MV[:2,3]  = (affine[:2,3] - np.array(img_size)/2)/scale\n",
    "    MV[3,3],MV[2,3] = 1, -200\n",
    "    \n",
    "#     t1,t2 = affine[0,3]/scale[0],affine[1,3]/scale[1]\n",
    "#     view_model = np.eye(4)\n",
    "#     view_model[:3,:3] = R_ortho[:3]\n",
    "#     view_model[:2,3]  = np.array([t1,t2])\n",
    "#     frustum = np.array([0.0,img_size[0]/scale[0],0.0,img_size[1]/scale[1]])\n",
    "#     ortho_projection = ortho(frustum)\n",
    "#     mvp = np.dot(ortho_projection, view_model)\n",
    "#     mvp[2,3] = -2\n",
    "#     viewport = np.array([0, img_size[1], img_size[0], -img_size[1]]) # flips y, origin top-left, like in OpenCV\n",
    "#     viewport_mat = np.array( [[viewport[2] / 2.0, 0.0, 0.0, viewport[2] / 2.0 + viewport[0]], \\\n",
    "#                               [0.0,               viewport[3] / 2.0, 0.0, viewport[3] / 2.0 + viewport[1]], \\\n",
    "#                               [0.0,               0.0,               1.0, 0.0], \\\n",
    "#                               [0.0,               0.0,               0.0, 1.0]]) \n",
    "#     full_projection = np.dot(viewport_mat, mvp)\n",
    "    affine = np.vstack((affine,np.array([0,0,0,1])))\n",
    "    return MV, affine, scale\n",
    "\n",
    "def findNearestCooresponding(image_points,model_points,affine):\n",
    "    points = np.hstack((model_points,np.ones((model_points.shape[0],1))))\n",
    "    reProjection = np.dot(affine,points.T).T\n",
    "    if reProjection.shape[1]>2:\n",
    "        reProjection /= reProjection[:,[2]]\n",
    "    model_ids = []\n",
    "    for item in image_points:\n",
    "        dis = np.sum(np.abs(reProjection[:,:2] - item.reshape((1,-1))),axis=1)\n",
    "        model_ids.append(np.argmin(dis))\n",
    "    return model_points[model_ids],model_ids\n",
    "\n",
    "def visLM(model_points, image_points, im,affine, homogeneous=False):\n",
    "    if homogeneous:\n",
    "        points = np.hstack((model_points,np.ones((model_points.shape[0],1))))\n",
    "    else:\n",
    "        points = model_points\n",
    "    points = np.dot(affine,points.T).T\n",
    "    points /= points[:,[2]]\n",
    "    for p in points:\n",
    "        cv2.circle(im, (int(p[0]), int(im.shape[0] - p[1])), 1, (0,255,0), -1)  \n",
    "    for p in image_points:\n",
    "        cv2.circle(im, (int(p[0]), int(im.shape[0] - p[1])), 1, (0,0,255), -1)  \n",
    "    return im\n",
    "\n",
    "def calReprojecErr(affine,point,lm):\n",
    "    point_img = np.dot(affine[:2,:3],point.T)+affine[:2,[3]]\n",
    "    return np.mean(np.abs(lm-point_img.T))                 \n",
    "    \n",
    "def buildEdgeTopology(mesh):\n",
    "    edges = []\n",
    "    for item in mesh.faces:\n",
    "        edges.append([item[0],item[1]])\n",
    "        edges.append([item[1],item[2]])\n",
    "        edges.append([item[2],item[0]])\n",
    "    return np.vstack(edges)\n",
    "\n",
    "def isFront(mesh,point_id):\n",
    "    z = mesh.vertices[:,2][point_id]\n",
    "    mask = z[:,0]>z[:,1]\n",
    "    front_id = np.unique(np.hstack((point_id[mask,0],point_id[~mask,1])))\n",
    "    return front_id\n",
    "\n",
    "def pointCloudClustering(vertices,thread):\n",
    "    isTravel = np.zeros(vertices.shape[0]).astype('bool')\n",
    "    while np.sum(isTravel) < vertices.shape[0]:\n",
    "        sample = np.where(isTravel)[0]\n",
    "        point = vertices[sample]\n",
    "        dis = np.sum(np.abs(vertices - point.reshape((1,-1))),axis=0)/3\n",
    "        ind = np.where(dis<thread)\n",
    "#         if isTravel[ind]\n",
    "    \n",
    "def findOcclusionEdge(mesh,MV,affine, contourLM, edge):\n",
    "    normal = np.dot(MV[:3,:3],mesh.vertex_normals.T).T\n",
    "    isBoundaries = normal[:,2][edge]>0\n",
    "    isBoundaries = isBoundaries[:,0]!=isBoundaries[:,1]\n",
    "    isBoundaries = np.where(isBoundaries)\n",
    "    point_id = []\n",
    "    for item in isBoundaries:\n",
    "        point_id.append(edge[item])\n",
    "    point_id = np.hstack(point_id)\n",
    "    \n",
    "    # Compute vertices that lye on occluding boundaries:\n",
    "    point_id = isFront(mesh,point_id)\n",
    "    points = mesh.vertices[point_id]\n",
    "    \n",
    "    # Project 3D boundaries to 2D\n",
    "    points = np.hstack((points,np.ones((points.shape[0],1))))\n",
    "    points_2D = np.dot(affine,points.T).T\n",
    "    \n",
    "    # Filter points far away\n",
    "    ids,ids_img = [],[]\n",
    "    threadHood = np.sum(np.abs(contourLM[0]-contourLM[-1]))/25\n",
    "    for i,item in enumerate(points_2D):\n",
    "        if  not contourMask[point_id[i]]:\n",
    "            continue\n",
    "\n",
    "        dis = np.sum(np.abs(contourLM-item.reshape((1,-1))),axis=1)\n",
    "        minimal_id = np.argmin(dis)\n",
    "        if dis[minimal_id] < threadHood:\n",
    "            ids.append(i)\n",
    "            ids_img.append(minimal_id)\n",
    "    point_id = point_id[ids]\n",
    "    return mesh.vertices[point_id],contourLM[ids_img], point_id\n",
    "\n",
    "def solvePCA(obj_base,affine,w,lm_base,ids,MODE,num_coeffs_to_fit=10,lamb=10.0):\n",
    "    #  affine*(v_base+ w_base*coef) = lm\n",
    "    # v_base n*3, w_base n*useBasis, coef useBasis*1, affine 3*4\n",
    "\n",
    "    if affine.ndim<3:\n",
    "        affine,lm_base = affine[np.newaxis],lm_base[np.newaxis]\n",
    "    \n",
    "    index,steps = [],[0]\n",
    "    for i in range(len(affine)):\n",
    "        steps.extend([len(lm_base[i])+steps[i]])\n",
    "        index.extend(list(np.ones(1).astype('uint8').repeat(len(lm_base[i]))*i))\n",
    "    \n",
    "\n",
    "    v_ind = ids['model_%s_ids'%MODE]\n",
    "    v_base = obj_base.reshape((-1,3))[v_ind]#\n",
    "    w_base = w.reshape((-1,3,w.shape[-1]))[v_ind][...,:num_coeffs_to_fit].reshape((-1,num_coeffs_to_fit))\n",
    "    \n",
    "    num_landmarks = v_base.shape[0]\n",
    "    y,v_bar = np.ones(3*num_landmarks),np.ones(4*num_landmarks)\n",
    "    V_hat_h = np.zeros((4 * num_landmarks, num_coeffs_to_fit))\n",
    "    P = np.zeros((3 * num_landmarks, 4 * num_landmarks))\n",
    "    for i in range(num_landmarks):\n",
    "        V_hat_h[i*4:i*4+3] = w_base[i*3:i*3+3]\n",
    "        P[i*3:i*3+3,i*4:i*4+4] = affine[index[i]]\n",
    "        y[i*3:i*3+2] = lm_base[index[i]][i-steps[index[i]]]\n",
    "        v_bar[4*i:4*i+3] = v_base[i]\n",
    "        \n",
    "    sigma_squared_2D = 3\n",
    "    Omega = np.eye(3 * num_landmarks)/sigma_squared_2D\n",
    "    \n",
    "    A = np.dot(P, V_hat_h)\n",
    "    b = np.dot(P, v_bar) - y\n",
    "    AtOmegaAReg = np.dot(np.dot(A.T,Omega), A) + lamb * np.eye(num_coeffs_to_fit)\n",
    "    rhs = - np.dot(np.dot(A.T, Omega), b)\n",
    "    \n",
    "    \n",
    "    # solve with qr\n",
    "    Q, R = np.linalg.qr(AtOmegaAReg)\n",
    "    y = np.dot(Q.T, rhs)\n",
    "    param = np.linalg.solve(R, y).reshape((-1,1))\n",
    "    obj_with_exp = obj_base + np.dot(w[...,:num_coeffs_to_fit],param)\n",
    "#     print(calReprojecErr(affine,obj_with_exp.reshape((-1,3))[ids['model_exp_ids']],lm_base))\n",
    "    return obj_with_exp,param\n",
    "\n",
    "    \n",
    "def optimizePose(mesh,lm,ids,steps=10,sha_coeffs_to_fit=50, exp_coeffs_to_fit=10,is_optimize_shape=True): \n",
    "    \n",
    "    image_5point_ids,model_5point_ids,model_ids,image_ids = ids['image_5point_ids'],ids['model_5point_ids'],ids['model_ids'],ids['image_ids']\n",
    "    model_points = mesh.vertices[model_5point_ids].astype('float32')\n",
    "    image_points = lm[image_5point_ids].astype('float32')\n",
    "    MV,affine,scale = solveCamera(model_points,image_points)\n",
    "\n",
    "    shape_coef, exp_coef = np.zeros((sha_coeffs_to_fit,1)), np.zeros((exp_coeffs_to_fit,1))\n",
    "    for iter in range(steps):\n",
    "\n",
    "        threadHood = 7.5/180*np.pi\n",
    "        angle = matrix2angle(MV[:3,:3])\n",
    "        model_points = mesh.vertices[model_5point_ids].astype('float32')\n",
    "        image_points = lm[image_5point_ids].astype('float32')\n",
    "        model_ids_new = np.array(model_5point_ids)\n",
    "\n",
    "        if  angle[1] < threadHood:\n",
    "            image_points_add, model_points_add = lm[image_ids[1]],mesh.vertices[model_ids[1]]\n",
    "            model_points_add, model_ids_add = findNearestCooresponding(image_points_add, model_points_add,affine)\n",
    "            \n",
    "            image_points = np.vstack((image_points,image_points_add))\n",
    "            model_points = np.vstack((model_points,model_points_add))\n",
    "            model_ids_new = np.hstack((model_ids_new,model_ids[1][model_ids_add]))\n",
    "\n",
    "        if angle[1] > -threadHood:\n",
    "            image_points_add, model_points_add = lm[image_ids[0]],mesh.vertices[model_ids[0]]\n",
    "            model_points_add, model_ids_add = findNearestCooresponding(image_points_add, model_points_add,affine)\n",
    "\n",
    "            image_points = np.vstack((image_points,image_points_add))\n",
    "            model_points = np.vstack((model_points,model_points_add))\n",
    "            model_ids_new = np.hstack((model_ids_new,model_ids[0][model_ids_add]))\n",
    "\n",
    "        MV,affine,scale = solveCamera(model_points,image_points)\n",
    "        contour_3D,contour_2D,model_ids_add = fitOccludingContour(mesh,angle,MV,affine[:2],lm,image_ids,edge)\n",
    "        image_points_temp = np.vstack((image_points,contour_2D))\n",
    "        model_points_temp = np.vstack((model_points,contour_3D))\n",
    "       \n",
    "        MV,affine,scale = solveCamera(model_points_temp,image_points_temp)\n",
    "        \n",
    "        angle = matrix2angle(MV[:3,:3])\n",
    "        contour_3D,contour_2D,model_ids_add = fitOccludingContour(mesh,angle,MV,affine[:2],lm,image_ids,edge)\n",
    "        image_points = np.vstack((image_points,contour_2D))\n",
    "        model_points = np.vstack((model_points,contour_3D))\n",
    "        model_ids_new = np.hstack((model_ids_new,model_ids_add))\n",
    "\n",
    "        if not is_optimize_shape:\n",
    "            return MV,affine,scale,image_points,model_ids_new,mesh\n",
    "        \n",
    "#         affine2 = np.vstack((affine,np.array([0,0,0,1])))\n",
    "        # optimize shape\n",
    "        ids['model_sha_ids'] = model_ids_new\n",
    "        obj_current = obj_base + np.dot(models['w_exp'][...,:exp_coeffs_to_fit],exp_coef)\n",
    "        _, shape_coef = solvePCA(obj_current,affine,models['w_shp'],image_points,ids,MODE='sha',num_coeffs_to_fit=sha_coeffs_to_fit)\n",
    "\n",
    "        # optimize expression\n",
    "        obj_current = obj_base + np.dot(models['w_shp'][...,:sha_coeffs_to_fit],shape_coef)\n",
    "        vertice,exp_coef = solvePCA(obj_current,affine,models['w_exp'],lm[ids['image_exp_ids']],ids,MODE='exp',num_coeffs_to_fit=exp_coeffs_to_fit)\n",
    "    \n",
    "        mesh.vertices = vertice.reshape((-1,3))\n",
    "    \n",
    "    return MV,affine,scale,image_points,model_ids_new,mesh\n",
    "\n",
    "def optimizePose_Multiply_Img(mesh,lm,ids,steps=10,sha_coeffs_to_fit=40, exp_coeffs_to_fit=10): \n",
    "    # lm: [N,68,2]\n",
    "    image_5point_ids,model_5point_ids,model_ids,image_ids = ids['image_5point_ids'],ids['model_5point_ids'],ids['model_ids'],ids['image_ids']\n",
    "    model_points = mesh.vertices[model_5point_ids].astype('float32')\n",
    "    image_points = lm[:,image_5point_ids].astype('float32')\n",
    "    \n",
    "    MVs,affines,scales = [],[],[]\n",
    "    for i in range(len(image_points)):\n",
    "        MV,affine,scale = solveCamera(model_points,image_points[i])\n",
    "        MVs.append(MV);affines.append(affine);scales.append(scale)\n",
    "\n",
    "    threadHood = 5.5/180*np.pi\n",
    "    shape_coef, exp_coef = np.zeros((sha_coeffs_to_fit,1)), np.zeros((exp_coeffs_to_fit,1))\n",
    "    for iter in range(steps):\n",
    "     \n",
    "        model_ids_new2, image_points2 = [],[]\n",
    "        affines2,MVs2, scales2 = [],[],[]\n",
    "        for i,(MV,affine) in enumerate(zip(MVs,affines)):\n",
    "            angle = matrix2angle(MV[:3,:3])\n",
    "\n",
    "            model_points = mesh.vertices[model_5point_ids].astype('float32')\n",
    "            image_points = lm[i,image_5point_ids].astype('float32')\n",
    "            model_ids_new = np.array(model_5point_ids)\n",
    "\n",
    "            if  angle[1] < threadHood and angle[1] > -2*threadHood:\n",
    "                image_points_add, model_points_add = lm[i,image_ids[1]],mesh.vertices[model_ids[1]]\n",
    "                model_points_add, model_ids_add = findNearestCooresponding(image_points_add, model_points_add,affine)\n",
    "\n",
    "                image_points = np.vstack((image_points,image_points_add))\n",
    "                model_points = np.vstack((model_points,model_points_add))\n",
    "                model_ids_new = np.hstack((model_ids_new,model_ids[1][model_ids_add]))\n",
    "\n",
    "            if angle[1] > -threadHood and angle[1] < 2*threadHood:\n",
    "                image_points_add, model_points_add = lm[i,image_ids[0]],mesh.vertices[model_ids[0]]\n",
    "                model_points_add, model_ids_add = findNearestCooresponding(image_points_add, model_points_add,affine)\n",
    "\n",
    "                image_points = np.vstack((image_points,image_points_add))\n",
    "                model_points = np.vstack((model_points,model_points_add))\n",
    "                model_ids_new = np.hstack((model_ids_new,model_ids[0][model_ids_add]))\n",
    "\n",
    "            MV,affine,scale = solveCamera(model_points,image_points)\n",
    "            contour_3D,contour_2D,model_ids_add = fitOccludingContour(mesh,angle,MV,affine[:2],lm[i],image_ids,edge)\n",
    "            image_points = np.vstack((image_points,contour_2D))\n",
    "            model_points = np.vstack((model_points,contour_3D))\n",
    "            model_ids_new = np.hstack((model_ids_new,model_ids_add))\n",
    "\n",
    "            MV,affine,scale = solveCamera(model_points,image_points)\n",
    "            affines2.append(affine)\n",
    "            MVs2.append(MV);scales2.append(scale)\n",
    "            model_ids_new2.append(model_ids_new.tolist()); image_points2.append(image_points)\n",
    "        affines2 = np.stack(affines2,axis=0)\n",
    "        \n",
    "        # optimize shape\n",
    "        ids['model_sha_ids'] = [item for sublist in model_ids_new2 for item in sublist]\n",
    "        obj_current = obj_base + np.dot(models['w_exp'][...,:exp_coeffs_to_fit],exp_coef)\n",
    "        _, shape_coef = solvePCA(obj_current,affines2,models['w_shp'],image_points2,ids,MODE='sha',num_coeffs_to_fit=sha_coeffs_to_fit)\n",
    "        \n",
    "        # optimize expression\n",
    "        obj_current = obj_base + np.dot(models['w_shp'][...,:sha_coeffs_to_fit],shape_coef)\n",
    "        vertice,exp_coef = solvePCA(obj_current,affines2,models['w_exp'],lm[:,ids['image_exp_ids']],ids,MODE='exp',num_coeffs_to_fit=exp_coeffs_to_fit)\n",
    "    \n",
    "        MVs,affines,scales = MVs2.copy(),affines2.copy(),scales2.copy()\n",
    "        mesh.vertices = vertice.reshape((-1,3))\n",
    "    \n",
    "    return MVs,affines2,scales,image_points2,model_ids_new2,mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import pickle\n",
    "\n",
    "def _get_suffix(filename):\n",
    "    \"\"\"a.jpg -> jpg\"\"\"\n",
    "    pos = filename.rfind('.')\n",
    "    if pos == -1:\n",
    "        return ''\n",
    "    return filename[pos + 1:]\n",
    "\n",
    "def _load(fp):\n",
    "    suffix = _get_suffix(fp)\n",
    "    if suffix == 'npy':\n",
    "        return np.load(fp)\n",
    "    elif suffix == 'pkl':\n",
    "        return pickle.load(open(fp, 'rb'))\n",
    "    \n",
    "def build_DDFA():\n",
    "    DDFA = {}\n",
    "    d = './DDFA/'\n",
    "    ourModel = sio.loadmat(osp.join(d,'ourModel.mat'))\n",
    "    verticeMask = np.repeat(ourModel['verticeMask'],3,axis=1).reshape((-1))>0\n",
    "    DDFA['tri'] = np.load(osp.join(d,'faces_1216.npy'))[[2,1,0]]\n",
    "    DDFA['uv'] = np.load(osp.join(d,'uvs.npy')).T\n",
    "\n",
    "    w_shp = _load(osp.join(d, 'w_shp_sim.npy'))\n",
    "    w_exp = _load(osp.join(d, 'w_exp_sim.npy'))  # simplified version\n",
    "    meta = _load(osp.join(d, 'param_whitening.pkl'))\n",
    "    # param_mean and param_std are used for re-whitening\n",
    "    param_mean = meta.get('param_mean').reshape((-1,1))\n",
    "    param_std = meta.get('param_std').reshape((1,-1))\n",
    "\n",
    "    # ours\n",
    "    u_shp = _load(osp.join(d, 'u_shp2.npy'))\n",
    "    u_exp = _load(osp.join(d, 'u_exp.npy'))\n",
    "    keypoints = _load(osp.join(d, 'keypoints_sim3.npy'))\n",
    "    w_shp,w_exp,u_exp = w_shp[verticeMask],w_exp[verticeMask],u_exp[verticeMask]\n",
    "    u = u_shp + u_exp + w_shp@param_mean[12:52] + w_exp@param_mean[52:]\n",
    "    w_shp,w_exp = w_shp*param_std[:,12:52],w_exp*param_std[:,52:]\n",
    "\n",
    "    DDFA['u'],DDFA['w_shp'],DDFA['w_exp'] = u/1e4,w_shp/1e4, w_exp/1e4\n",
    "    DDFA['param_mean'],DDFA['param_std'] = param_mean,param_std\n",
    "    DDFA['keypoints'],DDFA['verticeMask'] = keypoints,verticeMask\n",
    "\n",
    "    return DDFA\n",
    "\n",
    "\n",
    "def fitOccludingContour(mesh,angle,MV,affine,lm,image_ids,edge):\n",
    "    if angle[1]>= 0:\n",
    "        contour = lm[image_ids[1]]\n",
    "    else:\n",
    "        contour = lm[image_ids[0]]\n",
    "        \n",
    "    return findOcclusionEdge(mesh,MV,affine,contour,edge)\n",
    "\n",
    "\n",
    "def build_ids(keypoints):\n",
    "    keypoints = keypoints.reshape(-1)\n",
    "    # for expression\n",
    "    image_mouse_ids = np.array(range(48,68))\n",
    "    model_mouse_ids = keypoints[image_mouse_ids]\n",
    "    image_eye_ids   = np.array(range(36,48))\n",
    "    model_eye_ids   = keypoints[image_eye_ids]\n",
    "    image_exp_ids   = np.hstack((image_mouse_ids,image_eye_ids))\n",
    "    model_exp_ids   = np.hstack((model_mouse_ids,model_eye_ids))\n",
    "\n",
    "    # for shape\n",
    "    image_5point_ids = np.hstack((np.array([30,8]),np.array(range(36,48))))\n",
    "    model_5point_ids = keypoints[image_5point_ids]\n",
    "    image_5point_ids,model_5point_ids = np.hstack((image_5point_ids,image_mouse_ids)),np.hstack((model_5point_ids,model_mouse_ids))\n",
    "\n",
    "    image_ids = np.array([[0,1,2,3,4,5,6,7],[9,10,11,12,13,14,15,16]])\n",
    "    model_ids = keypoints[image_ids] # right left\n",
    "    \n",
    "    ids = {'image_5point_ids':image_5point_ids,'model_5point_ids':model_5point_ids,'model_ids':model_ids,'image_ids':image_ids, \\\n",
    "           'image_exp_ids':image_exp_ids, 'model_exp_ids':model_exp_ids}\n",
    "    \n",
    "    return ids\n",
    "\n",
    "def build_BFM(filename):\n",
    "    models = loadmat(filename)\n",
    "    sigma_exp,sigma = models['sigma_exp'],models['sigma']\n",
    "    models['w_shp'] = models['w']*np.repeat(sigma,models['w'].shape[0],axis=1).T\n",
    "    models['w_exp'] = models['w_exp']*np.repeat(sigma_exp,models['w_exp'].shape[0],axis=1).T\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_predictor = 'E:/mesh2face/shape_predictor_68_face_landmarks_dlib.dat'\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(shape_predictor)\n",
    "\n",
    "CameraMode = 'ortho'\n",
    "\n",
    "# BFM face model\n",
    "mesh = trimesh.load('./BFM/template.obj',process=False)\n",
    "edge = buildEdgeTopology(mesh)\n",
    "models = build_BFM('./BFM/Model_Shape_crop.mat')\n",
    "ids = build_ids(models['keypoints'])\n",
    "contourMask = models['contourMask'].reshape(-1)\n",
    "obj_base = models['mu']\n",
    "\n",
    "# DDFA FACE MODEL\n",
    "# mesh = trimesh.load('./DDFA/template.obj',process=False)\n",
    "# contourMask = np.load('./BFM/contourMask.npy').reshape(-1)\n",
    "# edge = buildEdgeTopology(mesh)\n",
    "# models = build_DDFA()\n",
    "# ids = build_ids(models['keypoints'])\n",
    "# obj_base = models['u']\n",
    "\n",
    "# BFM face model\n",
    "# mesh = trimesh.load('./BFM/obama.obj',process=False)\n",
    "# edge = buildEdgeTopology(mesh)\n",
    "# models = build_BFM('./BFM/Model_Shape.mat')\n",
    "# keypoints = np.load(osp.join('BFM', 'keypoints.npy')).astype('int')\n",
    "# contourMask = np.load('./BFM/contourMask.npy')\n",
    "# ids = build_ids(keypoints)\n",
    "# obj_base = models['mu_shape'] + models['mu_exp']\n",
    "\n",
    "scale = 1000\n",
    "models['w_exp'],models['w_shp'], obj_base = models['w_exp']/scale,models['w_shp']/scale, obj_base/scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shape from multi-view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, lms = load_imgs('sample/student')# path to your image folder\n",
    "img, lm = imgs.copy(), lms.copy()\n",
    "img_size = [img.shape[2], img.shape[1]]\n",
    "lm[...,1] = img_size[1] - lm[...,1]\n",
    "\n",
    "mesh.vertices = obj_base.reshape((-1,3))\n",
    "MV,affine,scale,image_points,model_ids,mesh = optimizePose_Multiply_Img(mesh,lm,ids,steps=5)\n",
    "    \n",
    "for frameID,im in enumerate(img):\n",
    "    \n",
    "    if CameraMode == 'ortho':\n",
    "        renderedImg, depth = render2(mesh,model=MV[frameID],scale=scale[frameID],resolution=im.shape[:2])\n",
    "    else:\n",
    "        renderedImg, depth = render(mesh,MV[frameID],scale[frameID][1,1],resolution=im.shape[:2])\n",
    "        \n",
    "    mask = np.sum(renderedImg,axis=2)>10\n",
    "    im[mask] = renderedImg[mask]*0.6 + im[mask]*0.4\n",
    "    \n",
    "    im = visLM(mesh.vertices[model_ids[frameID]],image_points[frameID],im, affine[frameID],homogeneous=True)\n",
    "#     im = visLM(mesh.vertices[model_exp_ids],lm[image_exp_ids],im, affine,homogeneous=True)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(im[...,::-1])\n",
    "    cv2.imwrite(os.path.join('result','%02d.png'%frameID),im)\n",
    "    np.savetxt(os.path.join('result','%02d.txt'%frameID),affine[frameID])\n",
    "mesh.export(os.path.join('result','res.obj'));\n",
    "\n",
    "# obj = loadObj('DDFA/template.obj')\n",
    "# obj['v'] = mesh.vertices\n",
    "# obj['vt'] = models['uv']\n",
    "# obj['f'][6:9] = obj['f'][:3]\n",
    "# saveObj(os.path.join('result','res.obj'),obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shape from single view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, lms = load_imgs('sample/student')\n",
    "img, lm = imgs.copy(), lms.copy()\n",
    "img_size = [img.shape[2], img.shape[1]]\n",
    "lm[...,1] = img_size[1] - lm[...,1]\n",
    "\n",
    "CameraMode = 'ortho'\n",
    "for frameID in range(len()):\n",
    "    im, lm = imgs[frameID].copy(), lms[frameID].copy()\n",
    "    img_size = (im.shape[1], im.shape[0])\n",
    "    lm[:,1] = img_size[1] - lm[:,1]\n",
    "\n",
    "    mesh.vertices = obj_base.reshape((-1,3))\n",
    "    MV,affine,scale,image_points,model_ids,mesh = optimizePose(mesh,lm,ids,steps=3)\n",
    "\n",
    "    renderedImg, depth = render2(mesh,model=MV,scale=scale,resolution=im.shape[:2])\n",
    "    mask = np.sum(renderedImg,axis=2)>0\n",
    "    im[mask] = renderedImg[mask]*0.6 + im[mask]*0.4\n",
    "#     im = renderedImg\n",
    "    \n",
    "    im = visLM(mesh.vertices[model_ids],image_points,im, affine,homogeneous=True)\n",
    "#     im = visLM(mesh.vertices[model_exp_ids],lm[image_exp_ids],im, affine,homogeneous=True)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(im[...,::-1])\n",
    "#     cv2.imwrite(os.path.join('result','%02d.png'%frameID),im)\n",
    "#     mesh.export(os.path.join('result','%02d.obj'%frameID));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pose estimation from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'CCTV-crop.avi'# path to video\n",
    "cap = cv2.VideoCapture(path)\n",
    "path_out = os.path.join(path[:-4] + '_3D.avi')\n",
    "out = cv2.VideoWriter(path_out, cv2.VideoWriter_fourcc(*'XVID'), 20,(512, 512))\n",
    "\n",
    "cams = []\n",
    "frameCount = -1\n",
    "CameraMode = 'ortho'\n",
    "success, img = cap.read()\n",
    "while success and frameCount<1e6:\n",
    "    frameCount += 1\n",
    "    im = cv2.resize(img, (512, 512))\n",
    "    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    lm = landmark_detect(gray)\n",
    "    if lm is None:\n",
    "        print(frameCount)\n",
    "        continue\n",
    "    \n",
    "    img_size = (im.shape[1], im.shape[0])\n",
    "    lm[:,1] = img_size[1] - lm[:,1]\n",
    "\n",
    "    mesh.vertices = obj_base.reshape((-1,3))\n",
    "    MV,affine,scale,image_points,model_ids,mesh = optimizePose(mesh,lm,ids,steps=3)\n",
    "    avatar_to_bfm = np.linalg.inv(np.array([[0.918,-0.012,-0.038,0.005],[0.014,0.918,0.034,0.09],[0.038,-0.035,0.917,0.018],[0,0,0,1]]))\n",
    "    \n",
    "    renderedImg, depth = render2(mesh,model=MV,scale=scale,resolution=im.shape[:2])\n",
    "    mask = np.sum(renderedImg,axis=2)>0\n",
    "    im[mask] = renderedImg[mask]*0.6 + im[mask]*0.4\n",
    "    im = visLM(mesh.vertices[model_ids],image_points,im, affine,homogeneous=True)\n",
    "    \n",
    "    MV = np.dot(MV,avatar_to_bfm)\n",
    "    cams.append({'frameID':frameCount,'scale':scale,'extrinsic':MV})\n",
    "    out.write(im.astype('uint8'))\n",
    "    success, img = cap.read()\n",
    "    \n",
    "cap.release()\n",
    "out.release()\n",
    "np.save('ams.npy',cams)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
